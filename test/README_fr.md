# Tests End-to-End LangChain

Ce r√©pertoire contient des scripts complets de tests end-to-end de l'architecture LangChain pour v√©rifier l'ensemble du processus depuis la saisie utilisateur frontend jusqu'√† la r√©ponse LLM.

## üìÅ Structure des Fichiers

```
test/
‚îú‚îÄ‚îÄ end-to-end-langchain-test.js    # Script principal de tests
‚îú‚îÄ‚îÄ run-e2e-test.js                 # Script d'ex√©cution des tests
‚îú‚îÄ‚îÄ .env.example                    # Exemple de configuration d'environnement
‚îú‚îÄ‚îÄ .env                           # Configuration r√©elle de l'environnement (√† cr√©er)
‚îú‚îÄ‚îÄ test-results/                  # R√©pertoire des r√©sultats de tests
‚îÇ   ‚îú‚îÄ‚îÄ langchain-e2e-test-results.json
‚îÇ   ‚îî‚îÄ‚îÄ langchain-e2e-test-report.html
‚îî‚îÄ‚îÄ README.md                      # Ce document
```

## üöÄ D√©marrage Rapide

### 1. Configuration de l'Environnement

Avant la premi√®re ex√©cution, vous devez configurer les variables d'environnement :

```bash
# Copier l'exemple de configuration d'environnement
cp .env.example .env

# √âditer le fichier .env pour effectuer les configurations n√©cessaires
# Particuli√®rement OPENAI_API_KEY (si vous testez des appels LLM r√©els)
```

### 2. Ex√©cuter les Tests

```bash
# Ex√©cuter des tests end-to-end complets
node run-e2e-test.js

# V√©rifier uniquement la configuration de l'environnement
node run-e2e-test.js --check

# Activer les appels LLM r√©els (n√©cessite une cl√© API valide)
node run-e2e-test.js --real-llm

# Sp√©cifier le port du serveur web
node run-e2e-test.js --port 8080

# Mode de sortie d√©taill√©e
node run-e2e-test.js --verbose
```

### 3. Visualiser le Rapport de Tests

Apr√®s avoir termin√© les tests, un serveur web sera automatiquement d√©marr√© pour afficher le rapport de tests :

- URL d'acc√®s par d√©faut : http://localhost:3001
- Point de terminaison API : http://localhost:3001/api/test-results

## üìä Contenu des Tests

### Langues de Test

Les tests couvrent les 7 langues suivantes :
- Chinois (zh-CN)
- Anglais (en-US) 
- Japonais (ja)
- Cor√©en (ko)
- Espagnol (es-ES)
- Portugais (pt-BR)
- Fran√ßais (fr)

### Cas de Test

Chaque langue inclut 5 cas de test :

1. **D√©clencheur d'outil get-flow** - Test du mot-cl√© "flux actuel"
2. **D√©clencheur d'outil get-node-info** - Test du mot-cl√© "n≈ìud actuel"
3. **D√©clencheur d'outil get-settings** - Test du mot-cl√© "configuration actuelle"
4. **D√©clencheur d'outil get-diagnostics** - Test du mot-cl√© "diagnostic actuel"
5. **Conversation en langage naturel** - Test "Pr√©senter Node-RED" (sans d√©clencheur d'outil)

### Informations Importantes Enregistr√©es

Chaque cas de test enregistre les informations suivantes :

- **a. Texte de saisie utilisateur** - Texte original simul√© que l'utilisateur a saisi sur la page
- **b. Mot-cl√© d√©tect√©** - Mot-cl√© que LangChain a re√ßu et identifi√©
- **c. D√©termination d'appel d'outil** - D√©cision du syst√®me d'appeler un outil
- **d. Type d'outil et contenu de retour** - Outil sp√©cifique appel√© et son r√©sultat de retour
- **e. Prompt newHuman concat√©n√© envoy√© au LLM** - Prompt final de l'utilisateur envoy√© au LLM
- **f. Prompt syst√®me envoy√© au LLM** - Prompt au niveau syst√®me
- **g. R√©ponse LLM** - R√©sultat de r√©ponse du mod√®le de langage large

## üîß Explication des Variables d'Environnement

### Configuration Requise

```bash
# Cl√© API OpenAI (pour les appels LLM r√©els)
OPENAI_API_KEY=your_openai_api_key_here

# Simulation de l'environnement Node-RED
TEST_FLOW_ID=test-flow-123
TEST_NODE_ID=test-node-456
TEST_CONFIG_NODE_ID=test-config-node
```

### Configuration Optionnelle

```bash
# Configuration du fournisseur LLM
TEST_LLM_PROVIDER=openai
TEST_LLM_MODEL=gpt-3.5-turbo

# Port du serveur web
TEST_WEB_PORT=3001

# Activer les appels LLM r√©els
ENABLE_REAL_LLM_CALLS=false

# Configuration de d√©bogage
DEBUG_MODE=true
LOG_LEVEL=info
```

## üìà Rapport de Tests

### Rapport Web

Le rapport HTML g√©n√©r√© apr√®s avoir termin√© les tests inclut :

- **R√©sum√© des tests** - Informations statistiques g√©n√©rales
- **Tableaux par langue** - R√©sultats d√©taill√©s des tests pour chaque langue
- **Affichage du statut** - Statut succ√®s/√©chec
- **Design responsive** - Adaptation √† diff√©rentes tailles d'√©cran

### Donn√©es JSON

Les donn√©es de test brutes sont sauvegard√©es au format JSON et peuvent √™tre utilis√©es pour :

- Analyse automatis√©e
- Int√©gration dans les pipelines CI/CD
- G√©n√©ration de rapports personnalis√©s

## üõ†Ô∏è Architecture Technique

### Processus de Test

1. **Initialisation de l'environnement** - V√©rification de la configuration, des d√©pendances et des variables d'environnement
2. **Simulation du frontend** - Simulation de la saisie utilisateur et de la d√©tection de mots-cl√©s
3. **Traitement du backend** - Appel au LangChain Manager pour traiter les demandes
4. **Ex√©cution d'outils** - Simulation ou ex√©cution r√©elle d'outils li√©s
5. **Interaction LLM** - Construction de prompts et obtention de r√©ponses LLM
6. **Enregistrement des r√©sultats** - Sauvegarde d'informations compl√®tes de la cha√Æne de traitement
7. **G√©n√©ration de rapports** - G√©n√©ration de rapports web et de donn√©es JSON

### Composants de Simulation

- **Mock Node-RED** - Simulation de l'environnement d'ex√©cution Node-RED
- **Mock Tools** - Simulation des r√©sultats d'ex√©cution d'outils
- **Mock LLM** - Simulation optionnelle des r√©ponses LLM

## üîç D√©pannage

### Probl√®mes Courants

1. **Variables d'environnement non configur√©es**
   ```bash
   # V√©rifier si le fichier .env existe et est configur√© correctement
   node run-e2e-test.js --check
   ```

2. **D√©pendances manquantes**
   ```bash
   # Installer les d√©pendances n√©cessaires
   npm install express dotenv
   ```

3. **Cl√© API invalide**
   ```bash
   # Tester en mode simulation
   node run-e2e-test.js
   # Ou configurer ENABLE_REAL_LLM_CALLS=false
   ```

4. **Port en cours d'utilisation**
   ```bash
   # Sp√©cifier un autre port
   node run-e2e-test.js --port 8080
   ```

### Mode D√©bogage

```bash
# Activer la sortie d√©taill√©e
node run-e2e-test.js --verbose

# Ou configurer dans .env
DEBUG_MODE=true
LOG_LEVEL=debug
```

## üìù D√©veloppement d'Extensions

### Ajouter une Nouvelle Langue

1. Ajouter le code de langue √† `TEST_CONFIG.languages`
2. Ajouter les cas de test correspondants √† `TEST_CONFIG.testCases`
3. V√©rifier que le fichier de configuration de langue correspondant existe

### Ajouter un Nouveau Cas de Test

```javascript
// Ajouter aux cas de test de la langue correspondante
{ 
    keyword: 'nouveau mot-cl√©', 
    expectedTool: 'new-tool', 
    description: 'description du nouveau cas de test' 
}
```

### Simulation d'Outils Personnalis√©s

Ajouter les r√©sultats de simulation de nouveaux outils √† l'objet `mockToolResults` dans la fonction `executeTestCase`.

## üìÑ Licence

Ce script de test suit la m√™me licence que le projet principal.

## ü§ù Contribution

Nous accueillons les Issues et Pull Requests pour am√©liorer le script de test !

---

**Note** : Ce script de test est bas√© sur la conception d'architecture d√©crite dans le document `LANGCHAIN_ARCHITECTURE.md` et assure la couverture de test du processus complet d'interaction utilisateur.